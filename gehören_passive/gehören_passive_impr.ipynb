{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_dep_news_trf\") #insert the name of the model you want to use (preload if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions #functions for normalization and sentence splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the deTenTen23 or OneMillionPostsCorpus corpus as an example\n",
    "df = pd.read_excel('OMPC_postswith_gehoeren.xlsx') #insert the name of your excel file (or csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_Post        17508\n",
      "CreatedAt      17508\n",
      "Headline        6267\n",
      "Sentence       17508\n",
      "sentence_id    17508\n",
      "dtype: int64\n",
      "   ID_Post                CreatedAt  \\\n",
      "0       40  2009-04-05 10:58:51.037   \n",
      "1      238  2014-08-13 09:55:10.240   \n",
      "2      341  2014-08-13 13:22:25.483   \n",
      "3      505  2014-08-14 17:02:57.707   \n",
      "4      530  2014-08-17 14:41:13.097   \n",
      "\n",
      "                                            Headline  \\\n",
      "0       derStandard ist weit mehr als nur \"Standard\"   \n",
      "1                       wie schon unten erwähnt ....   \n",
      "2                                                NaN   \n",
      "3  mein Kind ist Linkshänder und benutzt das Best...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                            Sentence  sentence_id  \n",
      "0  Aber es gehört zum Standard, täglich diese Zei...            1  \n",
      "1  saucenschöpfer mit schnabel und dazu gehören a...            2  \n",
      "2  ), alles links. Lechts und rinks zu unterschei...            3  \n",
      "3  In der VS hben sie einmal gekocht und mein Kin...            4  \n",
      "4  .... was rechtshändern vermutlich unmöglich is...            5  \n"
     ]
    }
   ],
   "source": [
    "# adding id numbers\n",
    "df['sentence_id'] = df.reset_index().index +1\n",
    "print(df.count())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Post</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>Headline</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>2009-04-05 10:58:51.037</td>\n",
       "      <td>derStandard ist weit mehr als nur \"Standard\"</td>\n",
       "      <td>1</td>\n",
       "      <td>Aber es gehört zum Standard, täglich diese Zei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>2014-08-13 09:55:10.240</td>\n",
       "      <td>wie schon unten erwähnt ....</td>\n",
       "      <td>2</td>\n",
       "      <td>saucenschöpfer mit schnabel und dazu gehören a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341</td>\n",
       "      <td>2014-08-13 13:22:25.483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>), alles links. Lechts und rinks zu unterschei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>505</td>\n",
       "      <td>2014-08-14 17:02:57.707</td>\n",
       "      <td>mein Kind ist Linkshänder und benutzt das Best...</td>\n",
       "      <td>4</td>\n",
       "      <td>In der VS hben sie einmal gekocht und mein Kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>530</td>\n",
       "      <td>2014-08-17 14:41:13.097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>.... was rechtshändern vermutlich unmöglich is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_Post                CreatedAt  \\\n",
       "0       40  2009-04-05 10:58:51.037   \n",
       "1      238  2014-08-13 09:55:10.240   \n",
       "2      341  2014-08-13 13:22:25.483   \n",
       "3      505  2014-08-14 17:02:57.707   \n",
       "4      530  2014-08-17 14:41:13.097   \n",
       "\n",
       "                                            Headline  sentence_id  \\\n",
       "0       derStandard ist weit mehr als nur \"Standard\"            1   \n",
       "1                       wie schon unten erwähnt ....            2   \n",
       "2                                                NaN            3   \n",
       "3  mein Kind ist Linkshänder und benutzt das Best...            4   \n",
       "4                                                NaN            5   \n",
       "\n",
       "                                                text  \n",
       "0  Aber es gehört zum Standard, täglich diese Zei...  \n",
       "1  saucenschöpfer mit schnabel und dazu gehören a...  \n",
       "2  ), alles links. Lechts und rinks zu unterschei...  \n",
       "3  In der VS hben sie einmal gekocht und mein Kin...  \n",
       "4  .... was rechtshändern vermutlich unmöglich is...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the text in the dataframe\n",
    "df['text'] = df['Sentence'].apply(functions.normalize_text)\n",
    "df = df.drop(columns=['Sentence'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID_Post                CreatedAt  \\\n",
      "0       40  2009-04-05 10:58:51.037   \n",
      "0       40  2009-04-05 10:58:51.037   \n",
      "0       40  2009-04-05 10:58:51.037   \n",
      "0       40  2009-04-05 10:58:51.037   \n",
      "0       40  2009-04-05 10:58:51.037   \n",
      "\n",
      "                                       Headline  sentence_id  \\\n",
      "0  derStandard ist weit mehr als nur \"Standard\"            1   \n",
      "0  derStandard ist weit mehr als nur \"Standard\"            1   \n",
      "0  derStandard ist weit mehr als nur \"Standard\"            1   \n",
      "0  derStandard ist weit mehr als nur \"Standard\"            1   \n",
      "0  derStandard ist weit mehr als nur \"Standard\"            1   \n",
      "\n",
      "                                                text  \\\n",
      "0  Aber es gehört zum Standard, täglich diese Zei...   \n",
      "0  Aber es gehört zum Standard, täglich diese Zei...   \n",
      "0  Aber es gehört zum Standard, täglich diese Zei...   \n",
      "0  Aber es gehört zum Standard, täglich diese Zei...   \n",
      "0  Aber es gehört zum Standard, täglich diese Zei...   \n",
      "\n",
      "                                        text_split_0  \\\n",
      "0                        Aber es gehört zum Standard   \n",
      "0                     täglich diese Zeitung zu lesen   \n",
      "0                      Nur bedauere ich als Kärntner   \n",
      "0   dass die zuständige Redakteurin das hohe Nive...   \n",
      "0                                           Standard   \n",
      "\n",
      "                                text_split_0_split_1  \\\n",
      "0                        Aber es gehört zum Standard   \n",
      "0                     täglich diese Zeitung zu lesen   \n",
      "0                      Nur bedauere ich als Kärntner   \n",
      "0   dass die zuständige Redakteurin das hohe Nive...   \n",
      "0                                           Standard   \n",
      "\n",
      "                                         final_split  \n",
      "0                        Aber es gehört zum Standard  \n",
      "0                     täglich diese Zeitung zu lesen  \n",
      "0                      Nur bedauere ich als Kärntner  \n",
      "0   dass die zuständige Redakteurin das hohe Nive...  \n",
      "0                                           Standard  \n",
      "ID_Post                 225793\n",
      "CreatedAt               225793\n",
      "Headline                 92414\n",
      "sentence_id             225793\n",
      "text                    225793\n",
      "text_split_0            225793\n",
      "text_split_0_split_1    225793\n",
      "final_split             225793\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the delimiters\n",
    "delimiters = [r'[^\\w\\s]', r'\\boder\\b', r'\\bund\\b']\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df = functions.split_and_explode(df, 'text', delimiters)\n",
    "print(df.head())\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['text_split_0', 'text_split_0_split_1']) #adjust if you have more  or less delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.count of        ID_Post                CreatedAt  \\\n",
      "0           40  2009-04-05 10:58:51.037   \n",
      "1          238  2014-08-13 09:55:10.240   \n",
      "2          341  2014-08-13 13:22:25.483   \n",
      "3          505  2014-08-14 17:02:57.707   \n",
      "4          530  2014-08-17 14:41:13.097   \n",
      "...        ...                      ...   \n",
      "17504  1011670  2016-06-01 17:37:39.323   \n",
      "17505  1011722  2016-06-02 08:46:27.943   \n",
      "17506  1011742  2016-06-03 02:23:48.523   \n",
      "17506  1011742  2016-06-03 02:23:48.523   \n",
      "17507  1011743  2016-06-03 02:25:20.677   \n",
      "\n",
      "                                                Headline  sentence_id  \\\n",
      "0           derStandard ist weit mehr als nur \"Standard\"            1   \n",
      "1                           wie schon unten erwähnt ....            2   \n",
      "2                                                    NaN            3   \n",
      "3      mein Kind ist Linkshänder und benutzt das Best...            4   \n",
      "4                                                    NaN            5   \n",
      "...                                                  ...          ...   \n",
      "17504                                                NaN        17505   \n",
      "17505                                                NaN        17506   \n",
      "17506                                                 2.        17507   \n",
      "17506                                                 2.        17507   \n",
      "17507                                                 1.        17508   \n",
      "\n",
      "                                                    text  \\\n",
      "0      Aber es gehört zum Standard, täglich diese Zei...   \n",
      "1      saucenschöpfer mit schnabel und dazu gehören a...   \n",
      "2      ), alles links. Lechts und rinks zu unterschei...   \n",
      "3      In der VS hben sie einmal gekocht und mein Kin...   \n",
      "4      .... was rechtshändern vermutlich unmöglich is...   \n",
      "...                                                  ...   \n",
      "17504  Naja, das hier ist eine Kolumne. In einer Kolu...   \n",
      "17505  Genau darum geht es mir ja, vor allem außenpol...   \n",
      "17506  Und zu Südtirol, warum sollte sich der mehrhei...   \n",
      "17506  Und zu Südtirol, warum sollte sich der mehrhei...   \n",
      "17507  Das Kosovo gehört laut UNO immer noch zu Serbi...   \n",
      "\n",
      "                                             final_split  gehören_yes  \n",
      "0                            Aber es gehört zum Standard         True  \n",
      "1        dazu gehören auch noch messer vom fischbesteck          True  \n",
      "2       rinks zu unterscheiden bedarf einer gehörigen...         True  \n",
      "3       dass der Löffel eigentlich rechts neben den T...         True  \n",
      "4       vor nicht allzu langer zeit habe ich ein inte...         True  \n",
      "...                                                  ...          ...  \n",
      "17504   Auch das gehört zum journalistischen Berufsfeld          True  \n",
      "17505                           Kosovo gehört zu Serbien         True  \n",
      "17506   Die gesamte Nachkriegsordnung von 1918 ist üb...         True  \n",
      "17506                                     Italien gehört         True  \n",
      "17507   Das Kosovo gehört laut UNO immer noch zu Serbien         True  \n",
      "\n",
      "[18330 rows x 7 columns]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matte\\AppData\\Local\\Temp\\ipykernel_24896\\3484620260.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df['gehören_yes']=df['final_split'].str.contains(r'geh(ö|oe|o)r*') #adjust the regex to your phenomenon\n"
     ]
    }
   ],
   "source": [
    "#pre-filtering\n",
    "df['gehören_yes']=df['final_split'].str.contains(r'geh(ö|oe|o)r*') #adjust the regex to your phenomenon\n",
    "df = df[df['gehören_yes']]\n",
    "\n",
    "print(df.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter sentences for the target\n",
    "target_lemma = 'gehören'        #adjust the lemma to your target phenomenon\n",
    "target_tag = 'VVPP'             #adjust the tag to your target phenomenon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract lemma\n",
    "def extract_lemma(text):\n",
    "    doc = nlp(text)\n",
    "    lemma = [token.text for token in doc if token.lemma_ == target_lemma]\n",
    "    return ', '.join(lemma)\n",
    "\n",
    "# Apply the function to the column and create a new column with the extracted verbs\n",
    "df['gehören'] = df['final_split'].apply(extract_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the closest VVPP tagged verb to gehören\n",
    "def extract_closest_tag(text):\n",
    "    doc = nlp(text)\n",
    "    # Find the lemma token\n",
    "    lemma_token = None\n",
    "    for token in doc:\n",
    "        if token.lemma_ == target_lemma:\n",
    "            lemma_token = token\n",
    "            break\n",
    "    \n",
    "    if not lemma_token:\n",
    "        return None\n",
    "    \n",
    "    # Find closest VVPP\n",
    "    closest_vvpp = None\n",
    "    min_distance = float('inf')\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.tag_ == target_tag and token.lemma_ != target_lemma:\n",
    "            # Check if there are any punctuation between the tokens\n",
    "            start_idx = min(lemma_token.i, token.i)\n",
    "            end_idx = max(lemma_token.i, token.i)\n",
    "            tokens_between = doc[start_idx:end_idx]\n",
    "            if not any(t.is_punct for t in tokens_between):\n",
    "                distance = abs(token.i - lemma_token.i)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_vvpp = token.text\n",
    "    \n",
    "    return closest_vvpp\n",
    "\n",
    "df['VVPP'] = df['final_split'].apply(extract_closest_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Post</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>Headline</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>final_split</th>\n",
       "      <th>gehören_yes</th>\n",
       "      <th>gehören</th>\n",
       "      <th>VVPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>2009-04-05 10:58:51.037</td>\n",
       "      <td>derStandard ist weit mehr als nur \"Standard\"</td>\n",
       "      <td>1</td>\n",
       "      <td>Aber es gehört zum Standard, täglich diese Zei...</td>\n",
       "      <td>Aber es gehört zum Standard</td>\n",
       "      <td>True</td>\n",
       "      <td>gehört</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>2014-08-13 09:55:10.240</td>\n",
       "      <td>wie schon unten erwähnt ....</td>\n",
       "      <td>2</td>\n",
       "      <td>saucenschöpfer mit schnabel und dazu gehören a...</td>\n",
       "      <td>dazu gehören auch noch messer vom fischbesteck</td>\n",
       "      <td>True</td>\n",
       "      <td>gehören</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341</td>\n",
       "      <td>2014-08-13 13:22:25.483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>), alles links. Lechts und rinks zu unterschei...</td>\n",
       "      <td>rinks zu unterscheiden bedarf einer gehörigen...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>505</td>\n",
       "      <td>2014-08-14 17:02:57.707</td>\n",
       "      <td>mein Kind ist Linkshänder und benutzt das Best...</td>\n",
       "      <td>4</td>\n",
       "      <td>In der VS hben sie einmal gekocht und mein Kin...</td>\n",
       "      <td>dass der Löffel eigentlich rechts neben den T...</td>\n",
       "      <td>True</td>\n",
       "      <td>gehört</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>530</td>\n",
       "      <td>2014-08-17 14:41:13.097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>.... was rechtshändern vermutlich unmöglich is...</td>\n",
       "      <td>vor nicht allzu langer zeit habe ich ein inte...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_Post                CreatedAt  \\\n",
       "0       40  2009-04-05 10:58:51.037   \n",
       "1      238  2014-08-13 09:55:10.240   \n",
       "2      341  2014-08-13 13:22:25.483   \n",
       "3      505  2014-08-14 17:02:57.707   \n",
       "4      530  2014-08-17 14:41:13.097   \n",
       "\n",
       "                                            Headline  sentence_id  \\\n",
       "0       derStandard ist weit mehr als nur \"Standard\"            1   \n",
       "1                       wie schon unten erwähnt ....            2   \n",
       "2                                                NaN            3   \n",
       "3  mein Kind ist Linkshänder und benutzt das Best...            4   \n",
       "4                                                NaN            5   \n",
       "\n",
       "                                                text  \\\n",
       "0  Aber es gehört zum Standard, täglich diese Zei...   \n",
       "1  saucenschöpfer mit schnabel und dazu gehören a...   \n",
       "2  ), alles links. Lechts und rinks zu unterschei...   \n",
       "3  In der VS hben sie einmal gekocht und mein Kin...   \n",
       "4  .... was rechtshändern vermutlich unmöglich is...   \n",
       "\n",
       "                                         final_split  gehören_yes  gehören  \\\n",
       "0                        Aber es gehört zum Standard         True   gehört   \n",
       "1    dazu gehören auch noch messer vom fischbesteck          True  gehören   \n",
       "2   rinks zu unterscheiden bedarf einer gehörigen...         True      NaN   \n",
       "3   dass der Löffel eigentlich rechts neben den T...         True   gehört   \n",
       "4   vor nicht allzu langer zeit habe ich ein inte...         True      NaN   \n",
       "\n",
       "   VVPP  \n",
       "0  None  \n",
       "1  None  \n",
       "2  None  \n",
       "3  None  \n",
       "4  None  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nan values the df\n",
    "nan_value = float(\"NaN\")\n",
    "df.replace(\"\", nan_value, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Post</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>Headline</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>final_split</th>\n",
       "      <th>gehören_yes</th>\n",
       "      <th>gehören</th>\n",
       "      <th>VVPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>533</td>\n",
       "      <td>2014-08-21 13:46:03.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>gehört im kindesalter umgelernt , ganz einfach.</td>\n",
       "      <td>gehört im kindesalter umgelernt</td>\n",
       "      <td>True</td>\n",
       "      <td>gehört</td>\n",
       "      <td>umgelernt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2642</td>\n",
       "      <td>2015-03-11 15:16:04.713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>diese praktikumsgehälter sind wirklich ein wit...</td>\n",
       "      <td>gehört abgeschafft</td>\n",
       "      <td>True</td>\n",
       "      <td>gehört</td>\n",
       "      <td>abgeschafft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3116</td>\n",
       "      <td>2015-03-15 01:21:54.553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>*piketty soll es natürlich heißen. es war scho...</td>\n",
       "      <td>es gehören mal ein paar dinge klar gestellt</td>\n",
       "      <td>True</td>\n",
       "      <td>gehören</td>\n",
       "      <td>gestellt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3166</td>\n",
       "      <td>2015-03-16 23:02:47.570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>das gehört ausgeschmückt und mit absätzen vers...</td>\n",
       "      <td>das gehört ausgeschmückt</td>\n",
       "      <td>True</td>\n",
       "      <td>gehört</td>\n",
       "      <td>ausgeschmückt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3243</td>\n",
       "      <td>2015-03-26 15:35:06.027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>Konkurrenzklauseln gehören abgeschafft. Sie si...</td>\n",
       "      <td>Konkurrenzklauseln gehören abgeschafft</td>\n",
       "      <td>True</td>\n",
       "      <td>gehören</td>\n",
       "      <td>abgeschafft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_Post                CreatedAt Headline  sentence_id  \\\n",
       "5       533  2014-08-21 13:46:03.700      NaN            6   \n",
       "38     2642  2015-03-11 15:16:04.713      NaN           39   \n",
       "53     3116  2015-03-15 01:21:54.553      NaN           54   \n",
       "55     3166  2015-03-16 23:02:47.570      NaN           56   \n",
       "57     3243  2015-03-26 15:35:06.027      NaN           58   \n",
       "\n",
       "                                                 text  \\\n",
       "5     gehört im kindesalter umgelernt , ganz einfach.   \n",
       "38  diese praktikumsgehälter sind wirklich ein wit...   \n",
       "53  *piketty soll es natürlich heißen. es war scho...   \n",
       "55  das gehört ausgeschmückt und mit absätzen vers...   \n",
       "57  Konkurrenzklauseln gehören abgeschafft. Sie si...   \n",
       "\n",
       "                                     final_split  gehören_yes  gehören  \\\n",
       "5               gehört im kindesalter umgelernt          True   gehört   \n",
       "38                            gehört abgeschafft         True   gehört   \n",
       "53   es gehören mal ein paar dinge klar gestellt         True  gehören   \n",
       "55                     das gehört ausgeschmückt          True   gehört   \n",
       "57        Konkurrenzklauseln gehören abgeschafft         True  gehören   \n",
       "\n",
       "             VVPP  \n",
       "5       umgelernt  \n",
       "38    abgeschafft  \n",
       "53       gestellt  \n",
       "55  ausgeschmückt  \n",
       "57    abgeschafft  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the rows with NaN\n",
    "df.dropna(subset = ['gehören', 'VVPP'], inplace =True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_Post        2690\n",
       "CreatedAt      2690\n",
       "Headline       1019\n",
       "sentence_id    2690\n",
       "text           2690\n",
       "final_split    2690\n",
       "gehören_yes    2690\n",
       "gehören        2690\n",
       "VVPP           2690\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID_Post                CreatedAt  \\\n",
      "5          533  2014-08-21 13:46:03.700   \n",
      "38        2642  2015-03-11 15:16:04.713   \n",
      "53        3116  2015-03-15 01:21:54.553   \n",
      "55        3166  2015-03-16 23:02:47.570   \n",
      "57        3243  2015-03-26 15:35:06.027   \n",
      "...        ...                      ...   \n",
      "17471  1010386  2016-06-01 07:58:53.327   \n",
      "17478  1010783  2016-06-01 00:04:20.483   \n",
      "17480  1010925  2016-06-01 15:14:48.713   \n",
      "17482  1011020  2016-05-31 18:50:56.873   \n",
      "17487  1011070  2016-05-31 20:35:05.293   \n",
      "\n",
      "                                                Headline  sentence_id  \\\n",
      "5                                                    NaN            6   \n",
      "38                                                   NaN           39   \n",
      "53                                                   NaN           54   \n",
      "55                                                   NaN           56   \n",
      "57                                                   NaN           58   \n",
      "...                                                  ...          ...   \n",
      "17471  Klar wollen nicht alle, die herkommen, nach Li...        17472   \n",
      "17478                                                NaN        17479   \n",
      "17480                                                NaN        17481   \n",
      "17482                        Also das wird ein Fest hier        17483   \n",
      "17487                                                NaN        17488   \n",
      "\n",
      "                                                    text  \\\n",
      "5        gehört im kindesalter umgelernt , ganz einfach.   \n",
      "38     diese praktikumsgehälter sind wirklich ein wit...   \n",
      "53     *piketty soll es natürlich heißen. es war scho...   \n",
      "55     das gehört ausgeschmückt und mit absätzen vers...   \n",
      "57     Konkurrenzklauseln gehören abgeschafft. Sie si...   \n",
      "...                                                  ...   \n",
      "17471  Haben sie leicht schon von welchen gehört die ...   \n",
      "17478  Ich lese diesen Kommentar im Bewusstsein, dass...   \n",
      "17480  Das Grundproblem ist - das Fleisch hat viel zu...   \n",
      "17482  Rau hat recht, aber leider keinen Sinn für Sat...   \n",
      "17487  Hr. Rauscher, sie sollten selbst mal in manche...   \n",
      "\n",
      "                                             final_split  gehören_yes  \\\n",
      "5                       gehört im kindesalter umgelernt          True   \n",
      "38                                    gehört abgeschafft         True   \n",
      "53           es gehören mal ein paar dinge klar gestellt         True   \n",
      "55                             das gehört ausgeschmückt          True   \n",
      "57                Konkurrenzklauseln gehören abgeschafft         True   \n",
      "...                                                  ...          ...   \n",
      "17471  Haben sie leicht schon von welchen gehört die ...         True   \n",
      "17478   Vielleicht gehören erst einmal die Prioritäte...         True   \n",
      "17480    Ein Burgerpatty gehört völlig flach hergestellt         True   \n",
      "17482   aber leider keinen Sinn für Satire Gerade die...         True   \n",
      "17487   Es gehört eine staatliche Sonderwirtschaftszo...         True   \n",
      "\n",
      "       gehören           VVPP  \n",
      "5       gehört      umgelernt  \n",
      "38      gehört    abgeschafft  \n",
      "53     gehören       gestellt  \n",
      "55      gehört  ausgeschmückt  \n",
      "57     gehören    abgeschafft  \n",
      "...        ...            ...  \n",
      "17471   gehört      hinwollen  \n",
      "17478  gehören        gesetzt  \n",
      "17480   gehört    hergestellt  \n",
      "17482  gehören        gezogen  \n",
      "17487   gehört     geschaffen  \n",
      "\n",
      "[2690 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "df.to_excel('gehören_passive_filtered_OMPC.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Domain\n",
       "de      85\n",
       "at      21\n",
       "com     19\n",
       "net      9\n",
       "ch       3\n",
       "org      2\n",
       "eu       2\n",
       "info     2\n",
       "blog     1\n",
       "news     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VVPP\n",
       "verboten        9\n",
       "gesehen         5\n",
       "abgeschafft     4\n",
       "diskutiert      3\n",
       "bestraft        3\n",
       "               ..\n",
       "entmachtet      1\n",
       "verbracht       1\n",
       "erlegt          1\n",
       "veranstaltet    1\n",
       "weggesperrt     1\n",
       "Name: count, Length: 110, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['VVPP'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
